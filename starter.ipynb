{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%cd ..\n!mv LLaMA LLaMA_main","metadata":{"execution":{"iopub.status.busy":"2024-10-28T16:57:06.415929Z","iopub.execute_input":"2024-10-28T16:57:06.416736Z","iopub.status.idle":"2024-10-28T16:57:07.475594Z","shell.execute_reply.started":"2024-10-28T16:57:06.416691Z","shell.execute_reply":"2024-10-28T16:57:07.474308Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd ..\n!rm -rf LLaMA\n!git clone https://github.com/TmBoris/LLaMA.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-28T19:11:49.150003Z","iopub.execute_input":"2024-10-28T19:11:49.150686Z","iopub.status.idle":"2024-10-28T19:11:51.645985Z","shell.execute_reply.started":"2024-10-28T19:11:49.150620Z","shell.execute_reply":"2024-10-28T19:11:51.644655Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"/kaggle/working\nCloning into 'LLaMA'...\nremote: Enumerating objects: 202, done.\u001b[K\nremote: Counting objects: 100% (202/202), done.\u001b[K\nremote: Compressing objects: 100% (134/134), done.\u001b[K\nremote: Total 202 (delta 80), reused 176 (delta 54), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (202/202), 63.80 KiB | 1.30 MiB/s, done.\nResolving deltas: 100% (80/80), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pwd\n!ls","metadata":{"execution":{"iopub.status.busy":"2024-10-28T19:11:51.648603Z","iopub.execute_input":"2024-10-28T19:11:51.649085Z","iopub.status.idle":"2024-10-28T19:11:53.684152Z","shell.execute_reply.started":"2024-10-28T19:11:51.649032Z","shell.execute_reply":"2024-10-28T19:11:53.683162Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"/kaggle/working\nLLaMA\n","output_type":"stream"}]},{"cell_type":"code","source":"# !rm LLaMA_main/train.py LLaMA_main/inference.py\n# !rm -rf LLaMA_main/src\n# !cp LLaMA/train.py LLaMA_main/train.py\n# !cp LLaMA/inference.py LLaMA_main/inference.py\n# !cp -r LLaMA/src LLaMA_main/src","metadata":{"execution":{"iopub.status.busy":"2024-10-28T19:12:14.574167Z","iopub.execute_input":"2024-10-28T19:12:14.574693Z","iopub.status.idle":"2024-10-28T19:12:14.580200Z","shell.execute_reply.started":"2024-10-28T19:12:14.574641Z","shell.execute_reply":"2024-10-28T19:12:14.579091Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# %cd LLaMA_main\n%cd LLaMA","metadata":{"execution":{"iopub.status.busy":"2024-10-28T19:12:15.264880Z","iopub.execute_input":"2024-10-28T19:12:15.265817Z","iopub.status.idle":"2024-10-28T19:12:15.271934Z","shell.execute_reply.started":"2024-10-28T19:12:15.265742Z","shell.execute_reply":"2024-10-28T19:12:15.270841Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"/kaggle/working/LLaMA\n","output_type":"stream"}]},{"cell_type":"code","source":"# %pip install -r requirements.txt","metadata":{"execution":{"iopub.status.busy":"2024-10-28T19:12:18.615461Z","iopub.execute_input":"2024-10-28T19:12:18.616207Z","iopub.status.idle":"2024-10-28T19:12:18.620239Z","shell.execute_reply.started":"2024-10-28T19:12:18.616164Z","shell.execute_reply":"2024-10-28T19:12:18.619166Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin(token=\"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\")","metadata":{"execution":{"iopub.status.busy":"2024-10-28T19:12:19.421128Z","iopub.execute_input":"2024-10-28T19:12:19.421875Z","iopub.status.idle":"2024-10-28T19:12:19.544987Z","shell.execute_reply.started":"2024-10-28T19:12:19.421831Z","shell.execute_reply":"2024-10-28T19:12:19.544137Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: read).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\n\nwandb.login(key=\"46c3b8e339b3fb22dc286204510c8af5b2c3e2e5\")","metadata":{"execution":{"iopub.status.busy":"2024-10-28T19:12:19.611024Z","iopub.execute_input":"2024-10-28T19:12:19.612028Z","iopub.status.idle":"2024-10-28T19:12:19.694742Z","shell.execute_reply.started":"2024-10-28T19:12:19.611985Z","shell.execute_reply":"2024-10-28T19:12:19.693900Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"!HYDRA_FULL_ERROR=1 python train.py trainer.override=True trainer.n_epochs=20","metadata":{"execution":{"iopub.status.busy":"2024-10-28T19:12:20.022962Z","iopub.execute_input":"2024-10-28T19:12:20.023663Z","iopub.status.idle":"2024-10-28T19:14:20.686783Z","shell.execute_reply.started":"2024-10-28T19:12:20.023623Z","shell.execute_reply":"2024-10-28T19:14:20.685526Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Logging git commit and patch...\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbspanfilov\u001b[0m (\u001b[33mmate-ball\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.3\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/LLaMA/wandb/run-20241028_191225-8197xuxs\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtesting\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/mate-ball/nlp_hw3_llama\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/mate-ball/nlp_hw3_llama/runs/8197xuxs\u001b[0m\nLoading dataset...\nTokenizing dataset...\nmodel initialized\nLLaMA(\n  (embeds): Embedding(32000, 16)\n  (blocks): ModuleList(\n    (0-1): 2 x LlamaBlock(\n      (rms): RMSNorm((256, 16), eps=None, elementwise_affine=True)\n      (attention): RoPEMaskedMultiheadAttention(\n        (heads): ModuleList(\n          (0-1): 2 x RoPEMaskedAttentionHead(\n            (w_q): Linear(in_features=16, out_features=8, bias=True)\n            (w_k): Linear(in_features=16, out_features=8, bias=True)\n            (w_v): Linear(in_features=16, out_features=8, bias=True)\n          )\n        )\n        (linear): Linear(in_features=16, out_features=16, bias=True)\n      )\n      (feedforward): Sequential(\n        (0): SwiGLU(\n          (linear1): Linear(in_features=16, out_features=16, bias=True)\n          (linear2): Linear(in_features=16, out_features=16, bias=True)\n          (silu): SiLU()\n        )\n        (1): Linear(in_features=16, out_features=16, bias=True)\n      )\n    )\n  )\n  (rms): RMSNorm((256, 16), eps=None, elementwise_affine=True)\n  (linear): Linear(in_features=16, out_features=32000, bias=True)\n)\nAll parameters: 1072096\nTrainable parameters: 1072096\ntrain:   0%|                                             | 0/50 [00:00<?, ?it/s]Train Epoch: 1 [0/50 (0%)] Loss: 10.556244\ntrain:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 49/50 [00:05<00:00,  8.68it/s]\n    epoch          : 1\n    loss           : 10.556243896484375\n    grad_norm      : 0.35657578706741333\ntrain:   0%|                                             | 0/50 [00:00<?, ?it/s]Train Epoch: 2 [0/50 (0%)] Loss: 10.387695\ntrain:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 49/50 [00:05<00:00,  9.26it/s]\n    epoch          : 2\n    loss           : 10.3876953125\n    grad_norm      : 0.36164334416389465\ntrain:   0%|                                             | 0/50 [00:00<?, ?it/s]Train Epoch: 3 [0/50 (0%)] Loss: 9.409332\ntrain:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 49/50 [00:05<00:00,  8.99it/s]\n    epoch          : 3\n    loss           : 9.409332275390625\n    grad_norm      : 0.4261917471885681\ntrain:   0%|                                             | 0/50 [00:00<?, ?it/s]Train Epoch: 4 [0/50 (0%)] Loss: 7.892273\ntrain:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 49/50 [00:05<00:00,  9.27it/s]\n    epoch          : 4\n    loss           : 7.89227294921875\n    grad_norm      : 0.42347094416618347\ntrain:   0%|                                             | 0/50 [00:00<?, ?it/s]Train Epoch: 5 [0/50 (0%)] Loss: 6.539848\ntrain:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 49/50 [00:05<00:00,  9.37it/s]\n    epoch          : 5\n    loss           : 6.539848327636719\n    grad_norm      : 0.4203382432460785\nSaving checkpoint: /kaggle/working/LLaMA/saved/testing/checkpoint-epoch5.pth ...\ntrain:   0%|                                             | 0/50 [00:00<?, ?it/s]Train Epoch: 6 [0/50 (0%)] Loss: 5.468735\ntrain:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 49/50 [00:05<00:00,  9.22it/s]\n    epoch          : 6\n    loss           : 5.4687347412109375\n    grad_norm      : 0.39764145016670227\ntrain:   0%|                                             | 0/50 [00:00<?, ?it/s]Train Epoch: 7 [0/50 (0%)] Loss: 4.638824\ntrain:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 49/50 [00:06<00:00,  8.06it/s]\n    epoch          : 7\n    loss           : 4.638824462890625\n    grad_norm      : 0.37917381525039673\ntrain:   0%|                                             | 0/50 [00:00<?, ?it/s]Train Epoch: 8 [0/50 (0%)] Loss: 3.961906\ntrain:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 49/50 [00:05<00:00,  9.05it/s]\n    epoch          : 8\n    loss           : 3.9619064331054688\n    grad_norm      : 0.370212584733963\ntrain:   0%|                                             | 0/50 [00:00<?, ?it/s]Train Epoch: 9 [0/50 (0%)] Loss: 3.390999\ntrain:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 49/50 [00:05<00:00,  8.68it/s]\n    epoch          : 9\n    loss           : 3.3909988403320312\n    grad_norm      : 0.3683660626411438\ntrain:   0%|                                             | 0/50 [00:00<?, ?it/s]Train Epoch: 10 [0/50 (0%)] Loss: 2.913815\ntrain:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 49/50 [00:05<00:00,  9.26it/s]\n    epoch          : 10\n    loss           : 2.9138145446777344\n    grad_norm      : 0.36435002088546753\nSaving checkpoint: /kaggle/working/LLaMA/saved/testing/checkpoint-epoch10.pth ...\ntrain:   0%|                                             | 0/50 [00:00<?, ?it/s]Train Epoch: 11 [0/50 (0%)] Loss: 2.520603\ntrain:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 49/50 [00:05<00:00,  9.20it/s]\n    epoch          : 11\n    loss           : 2.5206031799316406\n    grad_norm      : 0.3712593615055084\ntrain:   0%|                                             | 0/50 [00:00<?, ?it/s]Train Epoch: 12 [0/50 (0%)] Loss: 2.204739\ntrain:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 49/50 [00:05<00:00,  9.12it/s]\n    epoch          : 12\n    loss           : 2.2047386169433594\n    grad_norm      : 0.33408695459365845\ntrain:   0%|                                             | 0/50 [00:00<?, ?it/s]Train Epoch: 13 [0/50 (0%)] Loss: 1.958611\ntrain:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 49/50 [00:05<00:00,  9.10it/s]\n    epoch          : 13\n    loss           : 1.9586105346679688\n    grad_norm      : 0.3246871531009674\ntrain:   0%|                                             | 0/50 [00:00<?, ?it/s]Train Epoch: 14 [0/50 (0%)] Loss: 1.772249\ntrain:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 49/50 [00:05<00:00,  9.18it/s]\n    epoch          : 14\n    loss           : 1.7722492218017578\n    grad_norm      : 0.31739386916160583\ntrain:   0%|                                             | 0/50 [00:00<?, ?it/s]Train Epoch: 15 [0/50 (0%)] Loss: 1.636330\ntrain:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 49/50 [00:05<00:00,  8.67it/s]\n    epoch          : 15\n    loss           : 1.6363296508789062\n    grad_norm      : 0.3130858242511749\nSaving checkpoint: /kaggle/working/LLaMA/saved/testing/checkpoint-epoch15.pth ...\ntrain:   0%|                                             | 0/50 [00:00<?, ?it/s]Train Epoch: 16 [0/50 (0%)] Loss: 1.541229\ntrain:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 49/50 [00:05<00:00,  8.98it/s]\n    epoch          : 16\n    loss           : 1.541229248046875\n    grad_norm      : 0.3012256324291229\ntrain:   0%|                                             | 0/50 [00:00<?, ?it/s]Train Epoch: 17 [0/50 (0%)] Loss: 1.478264\ntrain:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 49/50 [00:05<00:00,  9.27it/s]\n    epoch          : 17\n    loss           : 1.4782638549804688\n    grad_norm      : 0.30333495140075684\ntrain:   0%|                                             | 0/50 [00:00<?, ?it/s]Train Epoch: 18 [0/50 (0%)] Loss: 1.440292\ntrain:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 49/50 [00:05<00:00,  9.04it/s]\n    epoch          : 18\n    loss           : 1.4402923583984375\n    grad_norm      : 0.2861408293247223\ntrain:   0%|                                             | 0/50 [00:00<?, ?it/s]Train Epoch: 19 [0/50 (0%)] Loss: 1.420940\ntrain:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 49/50 [00:05<00:00,  9.31it/s]\n    epoch          : 19\n    loss           : 1.4209403991699219\n    grad_norm      : 0.2833549380302429\ntrain:   0%|                                             | 0/50 [00:00<?, ?it/s]Train Epoch: 20 [0/50 (0%)] Loss: 1.413689\ntrain:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 49/50 [00:05<00:00,  9.24it/s]\n    epoch          : 20\n    loss           : 1.4136886596679688\n    grad_norm      : 0.28221744298934937\nSaving checkpoint: /kaggle/working/LLaMA/saved/testing/checkpoint-epoch20.pth ...\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
